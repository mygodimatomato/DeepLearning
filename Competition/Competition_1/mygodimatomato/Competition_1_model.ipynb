{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import ast\n",
    "import itertools\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "n = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Month', 'Weekday', 'Year', 'Day', 'Hour', 'title_bit_count', 'img_count', 'link_count', 'title_word_count', 'content_len', 'content_word_count'\n",
    "\n",
    "-----------------------------------------------------------\n",
    "括號內是 acc > 0.58 的權重\n",
    "'Month', 'Weekday', 'Year', 'Hour' -> 100% (100%)\n",
    "\n",
    "'Day' -> 85% (72%)\n",
    "\n",
    "'img_count' -> 89% (65%)\n",
    "\n",
    "'channel' -> 81%\n",
    "\n",
    "'content_len' -> 49% (48%) -> 59%\n",
    "\n",
    "'author' -> 56%\n",
    "\n",
    "'title_bit_count' -> 36% (48%) -> 53%\n",
    "\n",
    "'link_count' -> 40% (46%) -> 37%\n",
    "\n",
    "'title_word_count' -> 36% (49%) -> 37% (drop?)\n",
    "\n",
    "'content_word_count' -> 38% (47%) (drop)\n",
    "\n",
    "'categories_count' -> 16% (15%) (drop)\n",
    "\n",
    "'Minutes' -> 跟 categories_count 差不多 (drop)\n",
    "\n",
    "**author and channel is important**\n",
    "channel 權重大於 author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Id' 'Popularity' 'Page content' 'img_count' 'link_count' 'title'\n",
      " 'title_word_count' 'title_bit_count' 'content' 'content_len'\n",
      " 'content_word_count' 'categories' 'categories_count' 'channel' 'author'\n",
      " 'Weekday' 'Year' 'Month' 'Day' 'Hour' 'Minutes' 'Sec' 'Timezone']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets_processed/train_processed_2.csv')\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra features : title, content, categories\n",
    "X_train = df[['Month', 'Weekday', 'Year', 'Day', 'Hour', 'img_count', 'content_len', 'channel', 'author', 'categories']]\n",
    "y_train = df.iloc[:]['Popularity'].values\n",
    "y_train[y_train==-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train['title'] = X_train['title'].apply(ast.literal_eval)\n",
    "X_train['categories'] = X_train['categories'].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mygodimatomato/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenizer_author(text):\n",
    "    if type(text) == np.ndarray:\n",
    "        text = text[0]\n",
    "    authors = re.split(',', text)\n",
    "    for idx, author in enumerate(authors):\n",
    "        authors[idx] = re.sub(' ', '', author)\n",
    "    return authors\n",
    "    \n",
    "def tokenizer_channel(text):\n",
    "    if type(text) == np.ndarray:\n",
    "        text = text[0]\n",
    "    channels = re.split(',', text)\n",
    "    for idx, channel in enumerate(channels):\n",
    "        channels[idx] = re.sub(' ', '', channel)\n",
    "    return channels\n",
    "\n",
    "def tokenizer_title(list):\n",
    "    # word-stemming\n",
    "    stemmed_title = [stemmer.stem(word) for word in list]\n",
    "    # remove stopwords\n",
    "    cleaned_title = [word for word in stemmed_title if word not in stop]\n",
    "    return cleaned_title\n",
    "\n",
    "\n",
    "def tokenizer_categories(list):   \n",
    "    # word-stemming\n",
    "    stemmed_categories = [stemmer.stem(word) for word in list]\n",
    "    # remove stopwords\n",
    "    cleaned_categories = [word for word in stemmed_categories if word not in stop]\n",
    "    return cleaned_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train['title'] = X_train['title'].apply(tokenizer_title)\n",
    "# X_train['title'].to_csv('../datasets_processed/title.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the author\n",
    "vectorizer = CountVectorizer(tokenizer=tokenizer_author, lowercase=False)\n",
    "vectorized_data = vectorizer.fit_transform(X_train['author'])\n",
    "vectorized_author = pd.DataFrame(vectorized_data.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# preprocess the channel\n",
    "vectorizer = CountVectorizer(tokenizer=tokenizer_channel, lowercase=False)\n",
    "vectorized_data = vectorizer.fit_transform(X_train['channel'])\n",
    "vectorized_channel = pd.DataFrame(vectorized_data.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# preprocess the title\n",
    "# vectorizer = CountVectorizer(tokenizer=tokenizer_title, lowercase=False)\n",
    "# vectorized_data = vectorizer.fit_transform(X_train['title'])\n",
    "# vectorized_title = pd.DataFrame(vectorized_data.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# preprocess the categories\n",
    "vectorizer = CountVectorizer(tokenizer=tokenizer_categories, lowercase=False)\n",
    "vectorized_data = vectorizer.fit_transform(X_train['categories'])\n",
    "vectorized_categories = pd.DataFrame(vectorized_data.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vectorized_categories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Month' 'Weekday' 'Year' 'Day' 'Hour' 'img_count' 'content_len' 'channel'\n",
      " 'author' 'categories']\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing standardization for numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train[['Month', 'Weekday', 'Year', 'Day', 'Hour', 'img_count', 'content_len', ]] = scaler.fit_transform(X_train[['Month', 'Weekday', 'Year', 'Day', 'Hour', 'img_count', 'content_len']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['author'], axis=1)\n",
    "X_train = X_train.drop(['channel'], axis=1)\n",
    "X_train = X_train.drop(['categories'], axis=1)\n",
    "# X_train = pd.concat([X_train, vectorized_author], axis=1)\n",
    "# X_train = pd.concat([X_train, vectorized_channel], axis=1)\n",
    "X_train = pd.concat([X_train, vectorized_categories], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10906, number of negative: 11208\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 22114, number of used features: 669\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493172 -> initscore=-0.027315\n",
      "[LightGBM] [Info] Start training from score -0.027315\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10905, number of negative: 11209\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2233\n",
      "[LightGBM] [Info] Number of data points in the train set: 22114, number of used features: 656\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493127 -> initscore=-0.027496\n",
      "[LightGBM] [Info] Start training from score -0.027496\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10905, number of negative: 11209\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2248\n",
      "[LightGBM] [Info] Number of data points in the train set: 22114, number of used features: 655\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493127 -> initscore=-0.027496\n",
      "[LightGBM] [Info] Start training from score -0.027496\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10906, number of negative: 11209\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2263\n",
      "[LightGBM] [Info] Number of data points in the train set: 22115, number of used features: 660\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493149 -> initscore=-0.027404\n",
      "[LightGBM] [Info] Start training from score -0.027404\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 10906, number of negative: 11209\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2275\n",
      "[LightGBM] [Info] Number of data points in the train set: 22115, number of used features: 666\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493149 -> initscore=-0.027404\n",
      "[LightGBM] [Info] Start training from score -0.027404\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.597 (+/-0.009)\n"
     ]
    }
   ],
   "source": [
    "lbgm = LGBMClassifier(n_estimators=n, max_depth=10, learning_rate=0.1, random_state=0)\n",
    "scores = cross_val_score(estimator=lbgm, X=X_train.values, y=y_train, cv=5, scoring='roc_auc')\n",
    "print('%.3f (+/-%.3f)' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com = []\n",
    "acc = []\n",
    "attributes = X_train.columns.values\n",
    "for r in range(1, len(attributes) + 1):\n",
    "    for combination in itertools.combinations(attributes, r):\n",
    "        # if combination.__contains__('Month') and combination.__contains__('Weekday') and combination.__contains__('Year') and \\\n",
    "        #     combination.__contains__('Day') and combination.__contains__('Hour') and combination.__contains__('img_count') and \\\n",
    "        #     combination.__contains__('channel'):\n",
    "            tmp = X_train[list(combination)]\n",
    "            if combination.__contains__('author'):\n",
    "                tmp = tmp.drop(['author'], axis=1)\n",
    "                tmp = pd.concat([tmp, vectorized_author], axis=1)\n",
    "            if combination.__contains__('categories'):\n",
    "            # if combination.__contains__('title'):\n",
    "            #     tmp = tmp.drop(['title'], axis=1)\n",
    "            #     tmp = pd.concat([tmp, vectorized_title], axis=1)\n",
    "            if combination.__contains__('channel'):\n",
    "                tmp = tmp.drop(['channel'], axis=1)\n",
    "                tmp = pd.concat([tmp, vectorized_channel], axis=1)\n",
    "            # if combination.__contains__('content'):\n",
    "            lbgm = LGBMClassifier(n_estimators=n, max_depth=10, learning_rate=0.1, random_state=1, num_leaves=100)\n",
    "            scores = cross_val_score(estimator=lbgm, X=tmp.values, y=y_train, cv=5, scoring='roc_auc')\n",
    "            com.append(combination)\n",
    "            acc.append([scores.mean(), scores.std()])\n",
    "\n",
    "\n",
    "tmp = pd.DataFrame({'combination': com, 'accuracy': acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output validation result\n",
    "sorted_tmp = tmp.sort_values(by=['accuracy'], ascending=False)\n",
    "sorted_tmp.to_csv('../training_output/lgbm_2_acc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10, random_state=15)\n",
    "scores = cross_val_score(estimator=rf, X=tmp.values, y=y_train, cv=5, scoring='roc_auc')\n",
    "print('%.3f (+/-%.3f)' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com = []\n",
    "acc = []\n",
    "attributes = X_train.columns.values\n",
    "for r in range(1, len(attributes) + 1):\n",
    "    for combination in itertools.combinations(attributes, r):\n",
    "        # if combination.__contains__('Month') and combination.__contains__('Weekday') and combination.__contains__('Year') and \\\n",
    "        #     combination.__contains__('Day') and combination.__contains__('Hour') and combination.__contains__('img_count') and \\\n",
    "        #     combination.__contains__('channel'):\n",
    "            tmp = X_train[list(combination)]\n",
    "            if combination.__contains__('author'):\n",
    "                tmp = tmp.drop(['author'], axis=1)\n",
    "                tmp = pd.concat([tmp, vectorized_author], axis=1)\n",
    "            # if combination.__contains__('categories'):\n",
    "            # if combination.__contains__('title'):\n",
    "            #     tmp = tmp.drop(['title'], axis=1)\n",
    "            #     tmp = pd.concat([tmp, vectorized_title], axis=1)\n",
    "            if combination.__contains__('channel'):\n",
    "                tmp = tmp.drop(['channel'], axis=1)\n",
    "                tmp = pd.concat([tmp, vectorized_channel], axis=1)\n",
    "            rf = RandomForestClassifier(n_estimators=10, random_state=15)\n",
    "            scores = cross_val_score(estimator=rf, X=tmp.values, y=y_train, cv=5, scoring='roc_auc')\n",
    "            com.append(combination)\n",
    "            acc.append([scores.mean(), scores.std()])\n",
    "\n",
    "\n",
    "tmp = pd.DataFrame({'combination': com, 'accuracy': acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame({'combination': com, 'accuracy': acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output validation result\n",
    "sorted_tmp = tmp.sort_values(by=['accuracy'], ascending=False)\n",
    "sorted_tmp.to_csv('../training_output/random_forest_acc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543 (+/-0.005)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_val_score(estimator=knn, X=X_train.values, y=y_train, cv=5, scoring='roc_auc')\n",
    "print('%.3f (+/-%.3f)' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.579 (+/-0.009)\n",
      "0.574 (+/-0.007)\n",
      "0.575 (+/-0.009)\n",
      "0.577 (+/-0.011)\n",
      "0.581 (+/-0.011)\n",
      "0.582 (+/-0.011)\n",
      "0.585 (+/-0.011)\n",
      "0.568 (+/-0.005)\n",
      "0.568 (+/-0.004)\n",
      "0.574 (+/-0.006)\n",
      "0.574 (+/-0.006)\n",
      "0.573 (+/-0.006)\n",
      "0.572 (+/-0.009)\n",
      "0.576 (+/-0.009)\n",
      "0.576 (+/-0.009)\n",
      "0.577 (+/-0.009)\n",
      "0.576 (+/-0.008)\n",
      "0.578 (+/-0.011)\n",
      "0.579 (+/-0.011)\n",
      "0.580 (+/-0.009)\n",
      "0.581 (+/-0.011)\n",
      "0.585 (+/-0.012)\n",
      "0.562 (+/-0.003)\n",
      "0.570 (+/-0.005)\n",
      "0.569 (+/-0.004)\n",
      "0.568 (+/-0.004)\n",
      "0.570 (+/-0.004)\n",
      "0.569 (+/-0.004)\n",
      "0.569 (+/-0.005)\n",
      "0.574 (+/-0.006)\n",
      "0.574 (+/-0.006)\n",
      "0.572 (+/-0.007)\n",
      "0.572 (+/-0.007)\n",
      "0.572 (+/-0.009)\n",
      "0.571 (+/-0.009)\n",
      "0.578 (+/-0.009)\n",
      "0.577 (+/-0.008)\n",
      "0.579 (+/-0.009)\n",
      "0.577 (+/-0.008)\n",
      "0.579 (+/-0.009)\n",
      "0.579 (+/-0.012)\n",
      "0.583 (+/-0.010)\n",
      "0.562 (+/-0.003)\n",
      "0.563 (+/-0.003)\n",
      "0.562 (+/-0.003)\n",
      "0.570 (+/-0.004)\n",
      "0.569 (+/-0.004)\n",
      "0.569 (+/-0.004)\n",
      "0.570 (+/-0.003)\n",
      "0.571 (+/-0.004)\n",
      "0.570 (+/-0.004)\n",
      "0.574 (+/-0.006)\n",
      "0.572 (+/-0.007)\n",
      "0.573 (+/-0.007)\n",
      "0.572 (+/-0.009)\n",
      "0.579 (+/-0.008)\n",
      "0.579 (+/-0.009)\n",
      "0.562 (+/-0.004)\n",
      "0.563 (+/-0.003)\n",
      "0.562 (+/-0.003)\n",
      "0.570 (+/-0.005)\n",
      "0.572 (+/-0.004)\n",
      "0.573 (+/-0.006)\n",
      "0.563 (+/-0.003)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# X_train = pd.concat([X_train, vectorized_author], axis=1)\n",
    "# X_train = pd.concat([X_train, vectorized_channel], axis=1)\n",
    "# X_train = pd.concat([X_train, vectorized_categories], axis=1)\n",
    "X_train = df[['Month', 'Weekday', 'Year', 'Day', 'Hour', 'img_count', 'categories', 'author', 'channel']]\n",
    "com = []\n",
    "acc = []\n",
    "attributes = X_train.columns.values\n",
    "for r in range(1, len(attributes) + 1):\n",
    "    for combination in itertools.combinations(attributes, r):\n",
    "      if combination.__contains__('Month') and combination.__contains__('Weekday') and combination.__contains__('Year') :\n",
    "        tmp = X_train[list(combination)]\n",
    "        if combination.__contains__('author'):\n",
    "          tmp = tmp.drop(['author'], axis=1)\n",
    "          tmp = pd.concat([tmp, vectorized_author], axis=1)\n",
    "        if combination.__contains__('categories'):\n",
    "          tmp = tmp.drop(['categories'], axis=1)\n",
    "          tmp = pd.concat([tmp, vectorized_categories], axis=1)\n",
    "        if combination.__contains__('channel'):\n",
    "          tmp = tmp.drop(['channel'], axis=1)\n",
    "          tmp = pd.concat([tmp, vectorized_channel], axis=1)\n",
    "        knn = KNeighborsClassifier(n_neighbors=400)\n",
    "        scores = cross_val_score(estimator=knn, X=tmp.values, y=y_train, cv=5, scoring='roc_auc')\n",
    "        com.append(combination)\n",
    "        acc.append([scores.mean(), scores.std()])\n",
    "        print('%.3f (+/-%.3f)' % (scores.mean(), scores.std()))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output validation result\n",
    "tmp = pd.DataFrame({'combination': com, 'accuracy': acc})\n",
    "sorted_tmp = tmp.sort_values(by=['accuracy'], ascending=False)\n",
    "sorted_tmp.to_csv('../training_output/KNN_600_acc.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
