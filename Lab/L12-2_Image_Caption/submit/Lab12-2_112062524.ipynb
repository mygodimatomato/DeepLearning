{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 18:53:08.101408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 18:53:11.381468: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-11-30 18:53:11.382906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-11-30 18:53:11.398268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.89GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2023-11-30 18:53:11.398648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.89GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2023-11-30 18:53:11.399012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:85:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.89GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2023-11-30 18:53:11.399369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:86:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.89GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2023-11-30 18:53:11.399405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-11-30 18:53:11.403547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-11-30 18:53:11.403633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-11-30 18:53:11.405983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-30 18:53:11.406464: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-30 18:53:11.408982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-30 18:53:11.410044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-11-30 18:53:11.410396: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-11-30 18:53:11.412854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2023-11-30 18:53:11.421245: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-11-30 18:53:11.421699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.89GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2023-11-30 18:53:11.421737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-11-30 18:53:11.421769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-11-30 18:53:11.421795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-11-30 18:53:11.421819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-30 18:53:11.421844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-30 18:53:11.421869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-30 18:53:11.421894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-11-30 18:53:11.421918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-11-30 18:53:11.422718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 1\n",
      "2023-11-30 18:53:11.422770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-11-30 18:53:12.096739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-11-30 18:53:12.096780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      1 \n",
      "2023-11-30 18:53:12.096788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N \n",
      "2023-11-30 18:53:12.097706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:82:00.0, compute capability: 6.0)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll generate plots of attention in order to see which parts of an image\n",
    "# our model focuses on during captioning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn includes many helpful utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, Activation, Concatenate, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from './dataset/words_captcha/spec_train_val.txt'\n",
    "import glob\n",
    "\n",
    "img_list = []\n",
    "answer_list = []\n",
    "\n",
    "with open('./dataset/words_captcha/spec_train_val.txt', 'r') as f:\n",
    "  for line in f:\n",
    "    image, answer = line.strip().split()\n",
    "    answer_list.append('<start> ' + ' '.join(answer) + ' <end>')\n",
    "    img_list.append('./dataset/words_captcha/' + image+'.png')\n",
    "\n",
    "# so the words_captcha has some image that is not list in  spec_train_val.txt, \n",
    "# we need to add these image to the img_list\n",
    "tmp = set(glob.glob(f'./dataset/words_captcha/*.png')) - set(img_list)\n",
    "# sort the tmp \n",
    "tmp = sorted(tmp)\n",
    "img_list += tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum length of any caption in our dataset\n",
    "def calc_max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=\"<unk>\", \n",
    "                                                  filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "tokenizer.fit_on_texts(answer_list)\n",
    "answer_seqs = tokenizer.texts_to_sequences(answer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tokenized vectors\n",
    "answer_seqs = tokenizer.texts_to_sequences(answer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad each vector to the max_length of the captions\n",
    "answer_vector = tf.keras.preprocessing.sequence.pad_sequences(answer_seqs, padding='post')\n",
    "max_length = calc_max_length(answer_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start> t h u s <end>', '<start> w w w <end>', '<start> t i e d <end>', '<start> i d s <end>', '<start> j a m <end>', '<start> z o o <end>', '<start> a p p l e <end>', '<start> b i g <end>', '<start> l o t <end>', '<start> a b o v e <end>']\n",
      "[[ 2  9 18 17  6  3  0]\n",
      " [ 2 24 24 24  3  0  0]\n",
      " [ 2  9  8  4 13  3  0]\n",
      " [ 2  8 13  6  3  0  0]\n",
      " [ 2 26  5 16  3  0  0]\n",
      " [ 2 28  7  7  3  0  0]\n",
      " [ 2  5 15 15 11  4  3]\n",
      " [ 2 20  8 19  3  0  0]\n",
      " [ 2 11  7  9  3  0  0]\n",
      " [ 2  5 20  7 25  4  3]]\n"
     ]
    }
   ],
   "source": [
    "print(answer_list[:10])\n",
    "print(answer_vector[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the first 100,000 images as training data, the next 20,000 as validation data, and the rest (final 20,000) as testing data.\n",
    "img_train, img_valid, img_test = img_list[:100000], img_list[100000:120000], img_list[120000:]\n",
    "answer_train, answer_valid = answer_vector[:100000], answer_vector[100000:120000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 20000, 20000, 100000, 20000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_train), len(img_valid), len(img_test), len(answer_train), len(answer_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "BUFFER_SIZE = 5000\n",
    "LEARNING_RATE = 1e-4\n",
    "embedding_dim = 256\n",
    "units = 512\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "num_steps = len(img_train) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(img_name, cap):\n",
    "    img = tf.io.read_file(img_name)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = img/255*2-1\n",
    "    img = tf.image.resize(img, (160, 300))\n",
    "    return img, cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training = tf.data.Dataset.from_tensor_slices((img_train, answer_train))\n",
    "dataset_training = dataset_training.map(lambda item1, item2: tf.numpy_function(\n",
    "                    map_func, [item1, item2], [tf.float32, tf.int32]),\n",
    "                    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset_training = dataset_training.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "dataset_valid = tf.data.Dataset.from_tensor_slices((img_valid, answer_valid))\n",
    "dataset_valid = dataset_valid.map(lambda item1, item2: tf.numpy_function(\n",
    "                    map_func, [item1, item2], [tf.float32, tf.int32]),\n",
    "                    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset_valid = dataset_valid.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features = ResNet50(include_top=False, weights='imagenet', input_shape=(160, 300, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder / Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Encoder(tf.keras.Model):\n",
    "    # Since you have already extracted the features and dumped it using pickle\n",
    "    # This encoder passes those features through a Fully connected layer\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(CNN_Encoder, self).__init__()\n",
    "        # shape after fc == (batch_size, 64, embedding_dim)\n",
    "        self.fc = tf.keras.layers.Dense(embedding_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x\n",
    "\n",
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)\n",
    "\n",
    "        # hidden shape == (batch_size, hidden_size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "        # score shape == (batch_size, 64, hidden_size)\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "\n",
    "        # attention_weights shape == (batch_size, 64, 1)\n",
    "        # you get 1 at the last axis because you are applying score to self.V\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "class RNN_Decoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units, vocab_size):\n",
    "        super(RNN_Decoder, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc1 = tf.keras.layers.Dense(self.units)\n",
    "        self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.units)\n",
    "\n",
    "    def call(self, x, features, hidden):\n",
    "        # defining attention as a separate model\n",
    "        context_vector, attention_weights = self.attention(features, hidden)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # shape == (batch_size, max_length, hidden_size)\n",
    "        x = self.fc1(output)\n",
    "\n",
    "        # x shape == (batch_size * max_length, hidden_size)\n",
    "        x = tf.reshape(x, (-1, x.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size * max_length, vocab)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x, state, attention_weights\n",
    "\n",
    "    def reset_state(self, batch_size):\n",
    "        return tf.zeros((batch_size, self.units))\n",
    "\n",
    "encoder = CNN_Encoder(embedding_dim)\n",
    "decoder = RNN_Decoder(embedding_dim, units, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  \n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/ResNet50\"\n",
    "ckpt = tf.train.Checkpoint(model=extract_features,\n",
    "                           encoder=encoder,\n",
    "                           decoder=decoder,\n",
    "                           optimizer = optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(img_tensor, target):\n",
    "    loss = 0\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "    hidden = decoder.reset_state(batch_size=BATCH_SIZE) \n",
    "\n",
    "    with tf.GradientTape()as tape:\n",
    "        features = extract_features(img_tensor)\n",
    "        features = tf.reshape(features, (features.shape[0], -1, features.shape[3]))\n",
    "        features = encoder(features)\n",
    "\n",
    "        for i in range(1, target.shape[1]):\n",
    "            predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
    "            loss += loss_function(target[:, i], predictions)\n",
    "            dec_input = tf.expand_dims(target[:, i], 1)\n",
    "    \n",
    "    total_loss = (loss / int(target.shape[1]))\n",
    "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables + extract_features.trainable_variables\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "    return loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_tensor):\n",
    "    batch_size = img_tensor.shape[0]\n",
    "    dec_input = tf.expand_dims(\n",
    "        [tokenizer.word_index['<start>']] * batch_size, 1)\n",
    "\n",
    "    features = extract_features(img_tensor)\n",
    "    features = tf.reshape(features, (features.shape[0], -1, features.shape[3]))\n",
    "    features = encoder(features)\n",
    "\n",
    "    hidden = decoder.reset_state(batch_size=batch_size)\n",
    "\n",
    "    result = tf.expand_dims([tokenizer.word_index['<start>']] * batch_size, 1)\n",
    "    for _ in range(max_length):\n",
    "        predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
    "        predicted_id = tf.argmax(predictions, axis=1).numpy()\n",
    "        dec_input = tf.expand_dims(predicted_id, 1)\n",
    "        result = tf.concat([result, predicted_id.reshape((batch_size, 1))], axis=1)\n",
    "\n",
    "    return result\n",
    "\n",
    "def postprocess(segs):\n",
    "    result_list = []\n",
    "    for seq in segs:\n",
    "        result = ''\n",
    "        for s in seq[1:]:\n",
    "            if s == tokenizer.word_index['<end>']:\n",
    "                break\n",
    "            result += tokenizer.index_word[s]\n",
    "        result_list.append(result)\n",
    "    return result_list\n",
    "\n",
    "def evaluate(dataset_valid):\n",
    "    sample_count = 0\n",
    "    correct_count = 0\n",
    "    for img_tensor, target in dataset_valid:\n",
    "        pred_list = postprocess(predict(img_tensor).numpy())\n",
    "        real_list = postprocess(target.numpy())\n",
    "\n",
    "        for pred, real in zip(pred_list, real_list):\n",
    "            sample_count += 1\n",
    "            if pred == real:\n",
    "                correct_count += 1\n",
    "    print(f\"sample_count: {sample_count}, correct_count: {correct_count}\")\n",
    "    return correct_count / sample_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1:   0%|          | 0/2000 [00:00<?, ?it/s]2023-11-30 18:57:10.748892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-11-30 18:57:10.975356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-11-30 18:57:11.009146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "Epoch  1: 100%|██████████| 2000/2000 [10:26<00:00,  3.19it/s, loss=1.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_count: 20000, correct_count: 0\n",
      "Validation accuracy: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  2: 100%|██████████| 2000/2000 [10:13<00:00,  3.26it/s, loss=1.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_count: 20000, correct_count: 8\n",
      "Validation accuracy: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  3: 100%|██████████| 2000/2000 [10:13<00:00,  3.26it/s, loss=0.7]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_count: 20000, correct_count: 16481\n",
      "Validation accuracy: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  4: 100%|██████████| 2000/2000 [10:13<00:00,  3.26it/s, loss=0.0797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_count: 20000, correct_count: 17578\n",
      "Validation accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  5: 100%|██████████| 2000/2000 [10:13<00:00,  3.26it/s, loss=0.0457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_count: 20000, correct_count: 18472\n",
      "Validation accuracy: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  6: 100%|██████████| 2000/2000 [10:13<00:00,  3.26it/s, loss=0.0343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_count: 20000, correct_count: 18800\n",
      "Validation accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  7: 100%|██████████| 2000/2000 [10:13<00:00,  3.26it/s, loss=0.0257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_count: 20000, correct_count: 18848\n",
      "Validation accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  8: 100%|██████████| 2000/2000 [10:14<00:00,  3.26it/s, loss=0.0215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_count: 20000, correct_count: 18779\n",
      "Validation accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  9:   2%|▏         | 38/2000 [00:12<10:31,  3.10it/s, loss=0.0197]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524_resnet.ipynb Cell 29\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524_resnet.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m pbar \u001b[39m=\u001b[39m tqdm(dataset_training, total\u001b[39m=\u001b[39mnum_steps, desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m2d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524_resnet.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m (step, (img_tensor, target)) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(pbar):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524_resnet.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     batch_loss, t_loss \u001b[39m=\u001b[39m train_step(img_tensor, target)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524_resnet.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m t_loss\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524_resnet.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     pbar\u001b[39m.\u001b[39mset_postfix({\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m: total_loss\u001b[39m.\u001b[39mnumpy() \u001b[39m/\u001b[39m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)})\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    829\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    852\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    853\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    854\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    858\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2943\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1919\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    556\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    557\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    558\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    559\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    560\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    561\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "EPOCHS = 10\n",
    "start = time.time()\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dataset_training, total=num_steps, desc=f'Epoch {epoch + 1:2d}')\n",
    "    for (step, (img_tensor, target)) in enumerate(pbar):\n",
    "        batch_loss, t_loss = train_step(img_tensor, target)\n",
    "        total_loss += t_loss\n",
    "        pbar.set_postfix({'loss': total_loss.numpy() / (step + 1)})\n",
    "\n",
    "    loss_plot.append(total_loss / num_steps)\n",
    "    ckpt_manager.save()\n",
    "\n",
    "    score = evaluate(dataset_valid)\n",
    "    print(f'Validation accuracy: {score:.2f}')\n",
    "\n",
    "print('Time taken for {} epoch {} sec\\n'.format(EPOCHS - start_epoch, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_plot)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features = DenseNet121(include_top=False, weights='imagenet', input_shape=(160, 300, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  2:   0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 18:06:02.485964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-11-30 18:06:02.719237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-11-30 18:06:02.753226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "Epoch  2: 100%|██████████| 2000/2000 [10:12<00:00,  3.27it/s, loss=0.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_count: 20000, correct_count: 19152\n",
      "Validation accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  3: 100%|██████████| 2000/2000 [09:48<00:00,  3.40it/s, loss=0.0156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_count: 20000, correct_count: 19555\n",
      "Validation accuracy: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  4: 100%|██████████| 2000/2000 [09:49<00:00,  3.39it/s, loss=0.0111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_count: 20000, correct_count: 17642\n",
      "Validation accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  5: 100%|██████████| 2000/2000 [09:48<00:00,  3.40it/s, loss=0.00563]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb Cell 37\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     loss_plot\u001b[39m.\u001b[39mappend(total_loss \u001b[39m/\u001b[39m num_steps)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     ckpt_manager\u001b[39m.\u001b[39msave()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     score \u001b[39m=\u001b[39m evaluate(dataset_valid)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation accuracy: \u001b[39m\u001b[39m{\u001b[39;00mscore\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTime taken for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m epoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sec\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(EPOCHS \u001b[39m-\u001b[39m start_epoch, time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start))\n",
      "\u001b[1;32m/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb Cell 37\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m correct_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m img_tensor, target \u001b[39min\u001b[39;00m dataset_valid:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     pred_list \u001b[39m=\u001b[39m postprocess(predict(img_tensor)\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     real_list \u001b[39m=\u001b[39m postprocess(target\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m pred, real \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(pred_list, real_list):\n",
      "\u001b[1;32m/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb Cell 37\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m batch_size \u001b[39m=\u001b[39m img_tensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m dec_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     [tokenizer\u001b[39m.\u001b[39mword_index[\u001b[39m'\u001b[39m\u001b[39m<start>\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m*\u001b[39m batch_size, \u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m features \u001b[39m=\u001b[39m extract_features(img_tensor)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m features \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(features, (features\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, features\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m]))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.114.91.178/home/mygodimatomato/DeepLearning/Lab/L12-2_Image_Caption/Lab12-2_112062524.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m features \u001b[39m=\u001b[39m encoder(features)\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1012\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1008\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[1;32m   1010\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1014\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1015\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:424\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    407\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \n\u001b[1;32m    409\u001b[0m \u001b[39m  In this case `call` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39m      a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(\n\u001b[1;32m    425\u001b[0m       inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:560\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    557\u001b[0m   \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[0;32m--> 560\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mlayer(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    562\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(node\u001b[39m.\u001b[39mflat_output_ids, nest\u001b[39m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1012\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1008\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[1;32m   1010\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1014\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1015\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/keras/layers/merge.py:183\u001b[0m, in \u001b[0;36m_Merge.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[39mreturn\u001b[39;00m y\n\u001b[1;32m    182\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_merge_function(inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/keras/layers/merge.py:522\u001b[0m, in \u001b[0;36mConcatenate._merge_function\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_merge_function\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m--> 522\u001b[0m   \u001b[39mreturn\u001b[39;00m K\u001b[39m.\u001b[39;49mconcatenate(inputs, axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    202\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m    203\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    204\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:2989\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(tensors, axis)\u001b[0m\n\u001b[1;32m   2987\u001b[0m   \u001b[39mreturn\u001b[39;00m ragged_concat_ops\u001b[39m.\u001b[39mconcat(tensors, axis)\n\u001b[1;32m   2988\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2989\u001b[0m   \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39;49mconcat([to_dense(x) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m tensors], axis)\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    202\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m    203\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    204\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1677\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1673\u001b[0m     ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m   1674\u001b[0m         axis, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconcat_dim\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1675\u001b[0m         dtype\u001b[39m=\u001b[39mdtypes\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mget_shape()\u001b[39m.\u001b[39massert_has_rank(\u001b[39m0\u001b[39m)\n\u001b[1;32m   1676\u001b[0m     \u001b[39mreturn\u001b[39;00m identity(values[\u001b[39m0\u001b[39m], name\u001b[39m=\u001b[39mname)\n\u001b[0;32m-> 1677\u001b[0m \u001b[39mreturn\u001b[39;00m gen_array_ops\u001b[39m.\u001b[39;49mconcat_v2(values\u001b[39m=\u001b[39;49mvalues, axis\u001b[39m=\u001b[39;49maxis, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/for_tf/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:1189\u001b[0m, in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   1188\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   1190\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mConcatV2\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, values, axis)\n\u001b[1;32m   1191\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   1192\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "EPOCHS = 10\n",
    "start = time.time()\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dataset_training, total=num_steps, desc=f'Epoch {epoch + 1:2d}')\n",
    "    for (step, (img_tensor, target)) in enumerate(pbar):\n",
    "        batch_loss, t_loss = train_step(img_tensor, target)\n",
    "        total_loss += t_loss\n",
    "        pbar.set_postfix({'loss': total_loss.numpy() / (step + 1)})\n",
    "\n",
    "    loss_plot.append(total_loss / num_steps)\n",
    "    ckpt_manager.save()\n",
    "\n",
    "    score = evaluate(dataset_valid)\n",
    "    print(f'Validation accuracy: {score:.2f}')\n",
    "\n",
    "print('Time taken for {} epoch {} sec\\n'.format(EPOCHS - start_epoch, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_plot)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_test(img_name):\n",
    "    img = tf.io.read_file(img_name)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, (160, 300))\n",
    "    img = img/255*2-1\n",
    "    return img, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_testing = tf.data.Dataset.from_tensor_slices(img_test)\\\n",
    "                                .map(map_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\\\n",
    "                                .batch(50)\\\n",
    "                                .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the result to csv file, path = './Lab12-2_112062524.txt'\n",
    "# the format of the csv file is:\n",
    "# img_name - \"./dataset/words_captcha/\" , answer\n",
    "with open('./Lab12-2_112062524.txt', 'w') as f:\n",
    "    f.write('img_name,answer\\n')\n",
    "    for img_tensor, img_name in dataset_testing:\n",
    "        pred_list = postprocess(predict(img_tensor).numpy())\n",
    "        for img, pred in zip(img_name.numpy(), pred_list):\n",
    "            f.write(f'{img.decode()}, {pred}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the \"./dataset/words_captcha/\" and \".png\" from the img_name\n",
    "df = pd.read_csv('./Lab12-2_112062524.txt')\n",
    "df['img_name'] = df['img_name'].apply(lambda x: x[24:-4])\n",
    "df.to_csv('./Lab12-2_112062524_2.txt', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the Lab12-2_112062524_2.txt and delete all \",\" in the file\n",
    "# then save the file to Lab12-2_112062524_3.txt\n",
    "with open('./Lab12-2_112062524_2.txt', 'r') as f:\n",
    "    contents = f.read()\n",
    "contents = contents.replace(',', '')\n",
    "\n",
    "with open('./Lab12-2_112062524_3.txt', 'w') as f:\n",
    "    f.write(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "## Data Preprocess\n",
    "- 在 preprocess 的部分, 基本上就是用lab的內容, 並按照 hint 做處理, 並沒有做額外的處理\n",
    "## Encoder Decoder\n",
    "- 在 decoder 跟 encoder 的部分是把例子的直接拿來用 , 沒有做額外的更改(一部分也是因為我其實對\n",
    "RNN 不太熟, 也不知道要怎麼更改)\n",
    "\n",
    "## Model\n",
    "- 主要用了兩個不同的 pretrain model 來實作 feature extractor, 分別是 DenseNet121 跟 resNet50,\n",
    "- DenseNet121 : 可以從 training 結果看到如果用 DenseNet 在第一個 epoch 結束時整體的 performance 就非常高了, 會使用 denseNet 是因為看到了下面這篇文章\n",
    "  - https://www.aimspress.com/fileOther/PDF/MBE/mbe-16-05-292.pdf\n",
    "- ResNet50 : 會使用 ResNet 則是因為在過去修ML時有印象 ResNet50 的 performance 也非常優秀, 所以這次就好奇 resnet 的表現會如何, 可以看到 ResNet 的表現其實比 DenseNet 還差, 但是這其實也跟文獻上的結果一樣, 但是仍然能達到此次 lab 的要求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
